{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9WsWJ7Y1eVV"
      },
      "source": [
        "# Plastic Classifier\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/surfriderfoundationeurope/IA_Pau/blob/master/Hackaton_Surfrider_Getting_Started.ipynb)\n",
        "\n",
        "\n",
        "The goal is to build a plastic classifier, as the core detector / tracker is already built (but only works for generic plastic).\n",
        "\n",
        "If you want fast training, make sure you have a good GPU: check using the command `!nvidia-smi`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please install the required packages:   \n",
        "`pip install -r requirements.txt`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV_nmtVZ1y4f"
      },
      "source": [
        "### Getting the data\n",
        "\n",
        "To get the images of [taco](http://tacodataset.org/) project, you download the dataset from [here](https://www.kaggle.com/kneroma/tacotrashdataset).        \n",
        "Then put the `data` content folder in the `data/images/` folder of this repository, to have this structure:\n",
        "- `data/images/`\n",
        "    - `bach_1/`\n",
        "    - `bach_2/`\n",
        "    - `bach_3/`\n",
        "    - ...\n",
        "    - `annotations.json`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn0mpK_sNVLj"
      },
      "source": [
        "## Analyse the dataset\n",
        "\n",
        "the next following cells enable you to get a bit of information about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1je1TAgm5eks"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjrF1oan9oVv"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "from pycocotools.coco import COCO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "coco = COCO(annotation_file = './data/images/annotations/instances_train.json')\n",
        "\n",
        "coco_categories = coco.dataset['categories'][1:]\n",
        "\n",
        "nb_anns_per_cat = {cat['name']: len(coco.getAnnIds(catIds=[cat['id']])) for cat in coco_categories}\n",
        "nb_anns_per_cat = {k:v for k,v in sorted(nb_anns_per_cat.items(), key=lambda x: x[1], reverse=True)}\n",
        "cat_names = list(nb_anns_per_cat.keys())\n",
        "nb_images = list(nb_anns_per_cat.values())\n",
        "\n",
        "plt.bar(x = cat_names, height = nb_images)\n",
        "plt.xticks(range(len(cat_names)), cat_names, rotation='vertical')\n",
        "plt.ylabel('Number of annotations')\n",
        "plt.tight_layout()\n",
        "plt.autoscale(True)\n",
        "plt.savefig('dataset_analysis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndzdCs7C2rLP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from detection.coco_utils import CocoDetectionWithExif, ConvertCocoPolysToBboxes\n",
        "\n",
        "def get_dataset(root, image_set):\n",
        "    PATHS = {\n",
        "        \"train\": (\"images\", os.path.join(\"annotations\", \"instances_train.json\")),\n",
        "        \"val\": (\"images\", os.path.join(\"annotations\", \"instances_val.json\")),\n",
        "    }\n",
        "\n",
        "    img_folder, ann_file = PATHS[image_set]\n",
        "    img_folder = os.path.join(root, img_folder)\n",
        "    ann_file = os.path.join(root, ann_file)\n",
        "\n",
        "    dataset = CocoDetectionWithExif(img_folder, ann_file, transforms=ConvertCocoPolysToBboxes())\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzWI1i4L-YMD"
      },
      "outputs": [],
      "source": [
        "from detection.coco_utils import get_surfrider\n",
        "from detection import transforms\n",
        "\n",
        "base_size = 540\n",
        "crop_size = (544, 960)\n",
        "downsampling_factor = 4\n",
        "num_classes = 10\n",
        "path = '/content/surfnet/data/images/'\n",
        "\n",
        "# Building a train & test dataset\n",
        "train_dataset = get_dataset(path, \"train\")\n",
        "val_dataset = get_dataset(path, \"val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKaeAs534eH5"
      },
      "source": [
        "Let us display a full size picture, and corresponding bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQP9rfoB3zdh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x, y = next(iter(train_dataset))\n",
        "print(x.shape, y)\n",
        "plt.imshow(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Hackaton Surfrider Getting Started",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
