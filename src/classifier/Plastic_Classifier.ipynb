{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9WsWJ7Y1eVV"
      },
      "source": [
        "# Plastic Classifier\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/surfriderfoundationeurope/IA_Pau/blob/master/Hackaton_Surfrider_Getting_Started.ipynb)\n",
        "\n",
        "\n",
        "The goal is to build a plastic classifier, as the core detector / tracker is already built (but only works for generic plastic).\n",
        "\n",
        "If you want fast training, make sure you have a good GPU: check using the command `!nvidia-smi`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please install the required packages:   \n",
        "`pip install -r requirements.txt`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV_nmtVZ1y4f"
      },
      "source": [
        "### Getting the data\n",
        "\n",
        "```bash\n",
        "wget https://aka.ms/downloadazcopy-v10-linux\n",
        "```\n",
        "```bash\n",
        "tar -xvf downloadazcopy-v10-linux\n",
        "```\n",
        "\n",
        "```bash\n",
        "azcopy_linux_amd64_10.13.0/azcopy copy --recursive 'https://dataplasticoprod.blob.core.windows.net/images2label?sp=rl&st=2022-01-24T10:34:35Z&se=2022-01-31T18:34:35Z&spr=https&sv=2020-08-04&sr=c&sig=%2FHn2D3IvAECUJ0QqPpf0Jewo7GuNaIVYf23BjVjAd3Q%3D' './'\n",
        "```\n",
        "```bash\n",
        "mv images2label data/images/images\n",
        "```\n",
        "```bash\n",
        "mkdir -p data/images/annotations\n",
        "```\n",
        "```bash\n",
        "wget https://github.com/surfriderfoundationeurope/surfnet/releases/download/v01.2022/instances_train.json -P data/images/annotations/\n",
        "```\n",
        "```bash\n",
        "wget https://github.com/surfriderfoundationeurope/surfnet/releases/download/v01.2022/instances_val.json -P data/images/annotations/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import torch as th \n",
        "import cv2\n",
        "sys.path.append('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from eval import * \n",
        "from collections import defaultdict\n",
        "from tools.video_readers import SimpleVideoReader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_folder = '../../data/images/'\n",
        "model_folder = '../../models/'\n",
        "video_folder = '../../data/validation_videos/'\n",
        "tracking_folder = '../../experiments/tracking/'\n",
        "\n",
        "input_video = video_folder + 'T1/T1_1080_px_converted.mp4'\n",
        "input_mot_file = tracking_folder + 'mobilenet_v100_kappa_7_tau_4/T1_1080_px_converted_tracks.txt'\n",
        "crop_folder = './temp/crops'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detect trashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %run ../track.py --data_dir '../../data/validation_videos/T2/' --output_dir './temp/' --arch 'res_18' --device 'cpu' --noise_covariances_path '../../data/tracking_parameters' --skip_frames 3\n",
        "# %run ../overlay_tracking_results_on_video.py --input_video {input_video} --input_mot_file {input_mot_file} --skip_frames 3 --write True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from track import *\n",
        "from detection.detect import detect\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "arch = 'res_18'\n",
        "model_weights = None\n",
        "detection_threshold = 0.3\n",
        "noise_covariances_path = '../../data/tracking_parameters'\n",
        "video_path = '../../data/validation_videos/T2/T2_1080_px_converted.mp4'\n",
        "skip_frames = 3\n",
        "output_shape = (960,544)\n",
        "preload_frames = False\n",
        "downsampling_factor = 1\n",
        "detection_batch_size = 1\n",
        "display = Display(on=False, interactive=True)\n",
        "\n",
        "engine = get_tracker('EKF')\n",
        "\n",
        "print('---Loading model...')            \n",
        "model = load_model(arch=arch, model_weights=model_weights, device=device)\n",
        "print('Model loaded.')\n",
        "\n",
        "detector = lambda frame: detect(frame, threshold=detection_threshold, model=model)\n",
        "\n",
        "transition_variance = np.load(os.path.join(noise_covariances_path, 'transition_variance.npy'))\n",
        "observation_variance = np.load(os.path.join(noise_covariances_path, 'observation_variance.npy'))\n",
        "\n",
        "print(f'---Processing {video_path}')        \n",
        "reader = IterableFrameReader(video_filename=os.path.join(video_path), \n",
        "                                skip_frames=skip_frames,\n",
        "                                output_shape=output_shape,\n",
        "                                progress_bar=True,\n",
        "                                preload=preload_frames)\n",
        "\n",
        "\n",
        "input_shape = reader.input_shape\n",
        "output_shape = reader.output_shape\n",
        "ratio_y = input_shape[0] / (output_shape[0] // downsampling_factor)\n",
        "ratio_x = input_shape[1] / (output_shape[1] // downsampling_factor)\n",
        "\n",
        "print('Detecting...')\n",
        "detections = get_detections_for_video(reader, detector, batch_size=detection_batch_size, device=device)\n",
        "\n",
        "print('Tracking...')\n",
        "results = track_video(reader, iter(detections), downsampling_factor, engine, transition_variance, observation_variance, display)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_filename = os.path.join(video_path[:-4] +'.txt')\n",
        "write_tracking_results_to_file(results, ratio_x=ratio_x, ratio_y=ratio_y, output_filename=output_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get cropped images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mot file processed\n"
          ]
        }
      ],
      "source": [
        "def get_cropped_images(input_video, input_mot_file, crop_size, skip_frames):\n",
        "    # get the frame corresponding to the input_mot_file line\n",
        "    ret = True \n",
        "\n",
        "    # Get all the first frame of an object\n",
        "    with open(input_mot_file, 'r') as f: \n",
        "        results_raw = f.readlines()\n",
        "        results = defaultdict(list)\n",
        "        nb_object = 0\n",
        "        first_appear = []\n",
        "        for line in results_raw:\n",
        "            line = line.split(',')\n",
        "            if ((nb_object+1) == int(line[1])):\n",
        "                first_appear.append([int(line[0]) - 1, int(line[1]), int(float(line[2])), int(float(line[3]))])\n",
        "                nb_object += 1\n",
        "\n",
        "    print('Mot file processed')\n",
        "\n",
        "    current_frame_number = 0\n",
        "    cpt = 0\n",
        "\n",
        "    video = SimpleVideoReader(input_video, skip_frames=skip_frames)\n",
        "\n",
        "    while (ret and (cpt < nb_object)):\n",
        "        \n",
        "        ret, frame, frame_nb = video.read()\n",
        "        # detections_for_frame = results[frame_nb]\n",
        "\n",
        "        while ((current_frame_number+1) == first_appear[cpt]):\n",
        "            # crop the image\n",
        "            crop_img = frame[first_appear[cpt][2] - crop_size : first_appear[cpt][2] + crop_size,\n",
        "                             first_appear[cpt][3] - crop_size : first_appear[cpt][3] + crop_size]\n",
        "\n",
        "            try:\n",
        "                cv2.imwrite(crop_folder + 'crop' + str(int(cpt)) + '.jpg', crop_img) \n",
        "            except:\n",
        "                print('Error')\n",
        "\n",
        "            cpt += 1\n",
        "        \n",
        "        current_frame_number += 1\n",
        "\n",
        "        \n",
        "# gt = tag\n",
        "crop_size = 50\n",
        "skip_frames = 3\n",
        "get_cropped_images(input_video, input_mot_file, crop_size, skip_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show images\n",
        "and analyse them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting started"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Hackaton Surfrider Getting Started",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
